{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SadeemAlasiri/Ex_week3/blob/main/Copy_of_Boosting_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbXhuePolXKL"
      },
      "source": [
        "# Boosting Exercise\n",
        "\n",
        "In this exercise, you will learn about the Boosting technique, which is an ensemble method used to primarily reduce bias, and also variance in supervised learning. It combines multiple weak learners into a single strong learner. The learners are trained sequentially, each trying to correct its predecessor.\n",
        "\n",
        "## Dataset\n",
        "We will use the Breast Cancer dataset for this exercise. This dataset contains features computed from digitized images of breast mass and is used to predict whether the mass is malignant or benign. **Feel free to use another dataset!!**\n",
        "\n",
        "## Task\n",
        "Your task is to:\n",
        "1. Load the dataset.\n",
        "2. Preprocess the data (if necessary).\n",
        "3. Implement boosting models.\n",
        "4. Evaluate the models performance.\n",
        "\n",
        "Please fill in the following code blocks to complete the exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hTnB_ZUlo4l"
      },
      "source": [
        "## AdaBoost Tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbOTwlJ4lx40"
      },
      "source": [
        "### Step 1: Import Required Libraries\n",
        "First, import the necessary libraries for data manipulation, model training, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JfWrWb4Wk8hH"
      },
      "outputs": [],
      "source": [
        "# استعراض المكتبات\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUZB4tAnmLxP"
      },
      "source": [
        "### Step 2: Load and Preprocess the Dataset\n",
        "Load the dataset and preprocess it. This includes handling missing values, encoding categorical variables, and splitting the data into features and target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WVRRXzZDmOBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b357f7-ae09-4add-85bc-0df788f4a59d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-07 06:22:21--  https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘bank-additional.zip’\n",
            "\n",
            "bank-additional.zip     [   <=>              ] 434.15K   572KB/s    in 0.8s    \n",
            "\n",
            "2024-08-07 06:22:22 (572 KB/s) - ‘bank-additional.zip’ saved [444572]\n",
            "\n",
            "Archive:  bank-additional.zip\n",
            "   creating: bank-additional/\n",
            "  inflating: bank-additional/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/bank-additional/\n",
            "  inflating: __MACOSX/bank-additional/._.DS_Store  \n",
            "  inflating: bank-additional/.Rhistory  \n",
            "  inflating: bank-additional/bank-additional-full.csv  \n",
            "  inflating: bank-additional/bank-additional-names.txt  \n",
            "  inflating: bank-additional/bank-additional.csv  \n",
            "  inflating: __MACOSX/._bank-additional  \n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\"\n",
        "!wget $url # Download the zip file\n",
        "!unzip bank-additional.zip # Unzip the file\n",
        "data = pd.read_csv('bank-additional/bank-additional-full.csv', delimiter=';') # Load the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.get_dummies(data, drop_first=True)"
      ],
      "metadata": {
        "id": "pZ5t6ntTg_5n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj1kXkthmcpv"
      },
      "source": [
        "### Step 3: Split the Dataset\n",
        "Split the dataset into training and testing sets to evaluate the performance of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kKwDqYYrmeYQ"
      },
      "outputs": [],
      "source": [
        "X = data.drop('y_yes', axis=1)\n",
        "y = data['y_yes']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
      ],
      "metadata": {
        "id": "XfCDw_JQhEB_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkGTqL6OmtXW"
      },
      "source": [
        "### Step 4: Initialize and Train the AdaBoost Classifier\n",
        "Initialize a Decision Tree classifier and use it as the base estimator for the AdaBoost classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V9SHMVeFmsfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d01c194-65b2-48f7-ca11-c8537aade253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Accuracy: 90.84%\n"
          ]
        }
      ],
      "source": [
        "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "adaboost_classifier = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "\n",
        "predictions = adaboost_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'AdaBoost Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyHWV9HRm0T0"
      },
      "source": [
        "## XGBoost Tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqhPu5jfm8GB"
      },
      "source": [
        "### Step 1: Import Required Libraries\n",
        "First, import the necessary libraries for data manipulation, model training, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yDt8m9G9m6xA"
      },
      "outputs": [],
      "source": [
        "\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ax-nGSfntwM"
      },
      "source": [
        "### Step 2: Load and Preprocess the Dataset\n",
        "Load the dataset and preprocess it. This includes handling missing values, encoding categorical variables, and splitting the data into features and target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VW1t1XCxnxhC"
      },
      "outputs": [],
      "source": [
        "data = pd.get_dummies(data, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('y_yes', axis=1)\n",
        "y = data['y_yes']"
      ],
      "metadata": {
        "id": "HuWYEyXRhstM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXX_PSXSoHmp"
      },
      "source": [
        "### Step 3: Split the Dataset\n",
        "Split the dataset into training and testing sets to evaluate the performance of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Cdh8eq8zoIxi"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjBKszY3oN42"
      },
      "source": [
        "### Step 4: Initialize and Train the XGBoost Classifier\n",
        "Initialize and train the XGBoost classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zHkLiLENoRPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f182e20c-abad-42bf-dcc1-7763735e35d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Classifier Model Accuracy: 91.58%\n"
          ]
        }
      ],
      "source": [
        "xgb_classifier = XGBClassifier(n_estimators=50, random_state=42)\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'XGBoost Classifier Model Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC5D5c0hoUVc"
      },
      "source": [
        "## Gradient Boosting Tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8S9U-41oab4"
      },
      "source": [
        "### Step 1: Import Required Libraries\n",
        "First, import the necessary libraries for data manipulation, model training, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tJRkKxR9oYEK"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp5NR3ByoelM"
      },
      "source": [
        "### Step 2: Load and Preprocess the Dataset\n",
        "Load the dataset and preprocess it. This includes handling missing values, encoding categorical variables, and splitting the data into features and target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BPS8_qBrohcf"
      },
      "outputs": [],
      "source": [
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "\n",
        "X = data.drop('y_yes', axis=1)\n",
        "y = data['y_yes']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVjHzyr7opoL"
      },
      "source": [
        "### Step 3: Split the Dataset\n",
        "Split the dataset into training and testing sets to evaluate the performance of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IGe6bC74oq3q"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFkcaygKoyCG"
      },
      "source": [
        "### Step 4: Initialize and Train the Gradient Boosting Classifier\n",
        "Initialize and train the Gradient Boosting classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "N4saJTWeoxwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30dc18ab-96df-4c1f-8670-07d47629554a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Classifier Model Accuracy: 91.62%\n"
          ]
        }
      ],
      "source": [
        "gradient_boosting_classifier = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "gradient_boosting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = gradient_boosting_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Gradient Boosting Classifier Model Accuracy: {accuracy * 100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}